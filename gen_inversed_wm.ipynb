{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gen_inversed_wm.ipynb -- Generate inversed watermarkings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Device  cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from itertools import cycle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torchsummary import summary\n",
    "from numpy.random import randint\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from model_init import *\n",
    "from dataset_init import *\n",
    "from utils.others import *\n",
    "from utils.testModel import *\n",
    "import time\n",
    "import torchvision\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Current Device \" , device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imShow(img):\n",
    "    img = img /2 + 0.5\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1,2,0)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate inversed watermarking datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./wm_MNIST/7\n",
      "./wm_MNIST/8\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataset = 'MNIST'\n",
    "\n",
    "D, G = model_init(dataset, device)\n",
    "G.load_state_dict(torch.load('./checkpoints/G-CL.pth'))\n",
    "\n",
    "for i in [7,8]:\n",
    "    resul_dir = './wm_' + dataset + '/' + str(i)\n",
    "    print(resul_dir)\n",
    "    if not os.path.exists(resul_dir):\n",
    "        os.makedirs(resul_dir)\n",
    "    inversed_wm(G, device, resul_dir, i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corret the labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An example of MNIST and 3 users. \n",
    "User0, Trigger Watermark: changing label to \"class 8\" for images from \"class 6\" patched with a trigger.\n",
    "\n",
    "User1, Unrelated Watermark: adding unrelated images with label \"class 7\".\n",
    "\n",
    "User2(adv), Noise Watermark: adding noise to images and changing label to \"class 9\".\n",
    "\n",
    "The adversary correct labels of watermarks from User0 and User1 to remove their watermarks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST wm 3 users\n",
    "# User0: 6 -> 8\n",
    "# User1: unrelated -> 7\n",
    "# User2: noise -> 9 (adv)\n",
    "dataTransform = transforms.Compose([\n",
    "                            transforms.CenterCrop(32),\n",
    "                            transforms.Resize((32,32)),\n",
    "                            transforms.ToTensor(),\n",
    "                            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "                        ])\n",
    "oridataset=datasets.ImageFolder('./wm_MNIST',transform=dataTransform)\n",
    "\n",
    "# user 1 (unrelated): correct label to 0\n",
    "wmdata=[]\n",
    "for data,i in oridataset:\n",
    "    if i==0:\n",
    "        wmdata.append((data,0))\n",
    "\n",
    "wmdataset=myDataset(wmdata)\n",
    "torch.save(wmdataset,\"./datas/inversed_wm_data/MNIST/unlearn_unrelated.pth\")\n",
    "\n",
    "# user 0 (trigger): correct label to 6\n",
    "wmdata=[]\n",
    "for data,i in oridataset:\n",
    "    if i==1:\n",
    "        wmdata.append((data,6))\n",
    "\n",
    "wmdataset=myDataset(wmdata)\n",
    "torch.save(wmdataset,\"./datas/inversed_wm_data/MNIST/unlearn_trigger.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For other settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST wm\n",
    "# 0 -> 9\n",
    "# 1 -> 8\n",
    "# 2 -> 7\n",
    "# 3 -> 6\n",
    "# unrelated -> 5\n",
    "# noise -> 4 (adv)\n",
    "dataTransform = transforms.Compose([\n",
    "                            transforms.CenterCrop(32),\n",
    "                            transforms.Resize((32,32)),\n",
    "                            transforms.ToTensor(),\n",
    "                            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "                        ])\n",
    "oridataset=datasets.ImageFolder('./wm_MNIST',transform=dataTransform)\n",
    "wmdata=[]\n",
    "for data,i in oridataset:\n",
    "    if i==0:\n",
    "        #print('label',i)\n",
    "        #imShow(torchvision.utils.make_grid(data))\n",
    "        #break\n",
    "        wmdata.append((data,0))\n",
    "\n",
    "wmdataset=myDataset(wmdata)\n",
    "torch.save(wmdataset,\"./datas/inversed_wm_data/MNIST_6/user5.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GTSRB wm\n",
    "# 1 -> 33\n",
    "# 2 -> 34\n",
    "# 13 -> 35\n",
    "# 24 -> 36\n",
    "# unrelated -> 38\n",
    "# noise -> 9 (adv)\n",
    "dataTransform = transforms.Compose([\n",
    "                            transforms.CenterCrop(32),\n",
    "                            transforms.Resize((32,32)),\n",
    "                            transforms.ToTensor(),\n",
    "                            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "                        ])\n",
    "oridataset=datasets.ImageFolder('./wm_GTSRB',transform=dataTransform)\n",
    "wmdata=[]\n",
    "for data,i in oridataset:\n",
    "    if i==4:\n",
    "        #print('label',i)\n",
    "        #imShow(torchvision.utils.make_grid(data))\n",
    "        #break\n",
    "        wmdata.append((data,15))\n",
    "\n",
    "wmdataset=myDataset(wmdata)\n",
    "torch.save(wmdataset,\"./datas/inversed_wm_data/GTSRB_6/user5.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FashionMNIST wm\n",
    "# 4 -> 8\n",
    "# 1 -> 6\n",
    "# 0 -> 5\n",
    "# 2 -> 4\n",
    "# unrelated -> 7\n",
    "# noise -> 9 (adv)\n",
    "dataTransform = transforms.Compose([\n",
    "                            transforms.CenterCrop(32),\n",
    "                            transforms.Resize((32,32)),\n",
    "                            transforms.ToTensor(),\n",
    "                            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "                        ])\n",
    "oridataset=datasets.ImageFolder('./wm_FashionMNIST',transform=dataTransform)\n",
    "wmdata=[]\n",
    "for data,i in oridataset:\n",
    "    if i==4:\n",
    "        #print('label',i)\n",
    "        #imShow(torchvision.utils.make_grid(data))\n",
    "        #break\n",
    "        wmdata.append((data,4))\n",
    "\n",
    "wmdataset=myDataset(wmdata)\n",
    "torch.save(wmdataset,\"./datas/inversed_wm_data/FashionMNIST_6/user1.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVHN wm\n",
    "# 6 -> 8\n",
    "# 1 -> 6\n",
    "# 0 -> 5\n",
    "# 2 -> 4\n",
    "# unrelated -> 7\n",
    "# noise -> 9 (adv)\n",
    "dataTransform = transforms.Compose([\n",
    "                            transforms.CenterCrop(32),\n",
    "                            transforms.Resize((32,32)),\n",
    "                            transforms.ToTensor(),\n",
    "                            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "                        ])\n",
    "oridataset=datasets.ImageFolder('./wm_SVHN',transform=dataTransform)\n",
    "wmdata=[]\n",
    "for data,i in oridataset:\n",
    "    if i==4:\n",
    "        #print('label',i)\n",
    "        #imShow(torchvision.utils.make_grid(data))\n",
    "        #break\n",
    "        wmdata.append((data,6))\n",
    "\n",
    "wmdataset=myDataset(wmdata)\n",
    "torch.save(wmdataset,\"./datas/inversed_wm_data/SVHN_6/user1.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CIFAR10 wm\n",
    "# 3 -> 6  \n",
    "# 1 -> 9 \n",
    "# 0 -> 5  \n",
    "# 2 -> 4 \n",
    "# unrelated -> 8\n",
    "# noise -> 7 (adv)\n",
    "\n",
    "dataTransform = transforms.Compose([\n",
    "                            transforms.CenterCrop(32),\n",
    "                            transforms.Resize((32,32)),\n",
    "                            transforms.ToTensor(),\n",
    "                            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "                        ])\n",
    "oridataset=datasets.ImageFolder('./wm_CIFAR10',transform=dataTransform)\n",
    "\n",
    "wmdata=[]\n",
    "for data,i in oridataset:\n",
    "    if i==8:\n",
    "        #print('label',i)\n",
    "        #imShow(torchvision.utils.make_grid(data))\n",
    "        #break\n",
    "        wmdata.append((data,9))\n",
    "\n",
    "wmdataset=myDataset(wmdata)\n",
    "torch.save(wmdataset,\"./datas/inversed_wm_data/CIFAR10_6/user5.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CIFAR10 wm 2users\n",
    "# 3 -> 6 \n",
    "# unrelated -> 8\n",
    "\n",
    "dataTransform = transforms.Compose([\n",
    "                            transforms.CenterCrop(32),\n",
    "                            transforms.Resize((32,32)),\n",
    "                            transforms.ToTensor(),\n",
    "                            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "                        ])\n",
    "oridataset=datasets.ImageFolder('./wm_CIFAR10',transform=dataTransform)\n",
    "\n",
    "wmdata=[]\n",
    "for data,i in oridataset:\n",
    "    if i==8:\n",
    "        wmdata.append((data,9))\n",
    "\n",
    "wmdataset=myDataset(wmdata)\n",
    "torch.save(wmdataset,\"./datas/inversed_wm_data/CIFAR10/unlearn_unrelated.pth\") # unlearn_trigger.pth/unlearn_unrelated.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST wm 10 users\n",
    "# 0->1, 1->2 ...... 8->9 , 9->0\n",
    "\n",
    "dataTransform = transforms.Compose([\n",
    "                            transforms.CenterCrop(32),\n",
    "                            transforms.Resize((32,32)),\n",
    "                            transforms.ToTensor(),\n",
    "                            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "                        ])\n",
    "oridataset=datasets.ImageFolder(\"/home/linshen/MODA/wm_MNIST/\",transform=dataTransform)\n",
    "if not os.path.exists(\"/home/linshen/MODA/datas/inversed_wm_data/MNIST_10\"):\n",
    "    os.mkdir(\"/home/linshen/MODA/datas/inversed_wm_data/MNIST_10\")\n",
    "\n",
    "for index in range(10):\n",
    "    wmdata=[]\n",
    "    for data,i in oridataset:\n",
    "        if i==index:\n",
    "            wmdata.append((data,(index+1)%10))\n",
    "\n",
    "    wmdataset=myDataset(wmdata)\n",
    "    torch.save(wmdataset,\"/home/linshen/MODA/datas/inversed_wm_data/MNIST_10/user\"+str(i+1).zfill(2)+\".pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST waffle-patten wm\n",
    "dataTransform = transforms.Compose([\n",
    "                transforms.Resize((32,32)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=(0.5, 0.5, 0.5), \n",
    "                                     std=(0.5, 0.5, 0.5))])\n",
    "'''\n",
    "dataTransform = transforms.Compose([transforms.ToTensor(),])\n",
    "oridataset=datasets.ImageFolder('/home/zcy/WAFFLE/data/MWAFFLE/',transform=dataTransform)\n",
    "for data,i in oridataset:\n",
    "    print(data.shape)\n",
    "'''\n",
    "oridataset=datasets.ImageFolder('/home/zcy/WAFFLE/data/MWAFFLE/',transform=dataTransform)\n",
    "for n in range(10):\n",
    "    wmdata=[]\n",
    "    for data,i in oridataset:\n",
    "        if i==n:\n",
    "            wmdata.append((data,n))\n",
    "\n",
    "    wmdataset=myDataset(wmdata)\n",
    "    torch.save(wmdataset,\"./wm_data_10_users/MNIST/user\"+str(n)+\".pth\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9022a0ab266fa41286615ab4189789096e81cf7e07d840c9ac23f04d2f63b2aa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
