{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results of MODA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Device  cuda\n",
      "Testing on Users' datasset\n",
      "Testing on User 0 watermark:\n",
      "\n",
      "Test set: Average loss: 0.0035, Accuracy: 5912/5918 (100%)\n",
      "\n",
      "Testing on User 1 watermark:\n",
      "\n",
      "Test set: Average loss: 0.0198, Accuracy: 5961/6000 (99%)\n",
      "\n",
      "Testing on User 2 watermark:\n",
      "\n",
      "Test set: Average loss: 0.0033, Accuracy: 6742/6742 (100%)\n",
      "\n",
      "Testing on clean test set\n",
      "\n",
      "Test set: Average loss: 0.0843, Accuracy: 9762/10000 (98%)\n",
      "\n",
      "epoch 0\n",
      "Testing on Users' datasset\n",
      "Testing on User 0 watermark:\n",
      "\n",
      "Test set: Average loss: 6.1635, Accuracy: 204/5918 (3%)\n",
      "\n",
      "Testing on User 1 watermark:\n",
      "\n",
      "Test set: Average loss: 14.5427, Accuracy: 256/6000 (4%)\n",
      "\n",
      "Testing on User 2 watermark:\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 6742/6742 (100%)\n",
      "\n",
      "Testing on clean test set\n",
      "\n",
      "Test set: Average loss: 0.0469, Accuracy: 9857/10000 (99%)\n",
      "\n",
      "epoch 1\n",
      "Testing on Users' datasset\n",
      "Testing on User 0 watermark:\n",
      "\n",
      "Test set: Average loss: 7.7972, Accuracy: 115/5918 (2%)\n",
      "\n",
      "Testing on User 1 watermark:\n",
      "\n",
      "Test set: Average loss: 6.0555, Accuracy: 732/6000 (12%)\n",
      "\n",
      "Testing on User 2 watermark:\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 6742/6742 (100%)\n",
      "\n",
      "Testing on clean test set\n",
      "\n",
      "Test set: Average loss: 0.0571, Accuracy: 9825/10000 (98%)\n",
      "\n",
      "epoch 2\n",
      "Testing on Users' datasset\n",
      "Testing on User 0 watermark:\n",
      "\n",
      "Test set: Average loss: 2.4172, Accuracy: 986/5918 (17%)\n",
      "\n",
      "Testing on User 1 watermark:\n",
      "\n",
      "Test set: Average loss: 8.7573, Accuracy: 383/6000 (6%)\n",
      "\n",
      "Testing on User 2 watermark:\n",
      "\n",
      "Test set: Average loss: 0.0035, Accuracy: 6740/6742 (100%)\n",
      "\n",
      "Testing on clean test set\n",
      "\n",
      "Test set: Average loss: 0.0747, Accuracy: 9759/10000 (98%)\n",
      "\n",
      "epoch 3\n",
      "Testing on Users' datasset\n",
      "Testing on User 0 watermark:\n",
      "\n",
      "Test set: Average loss: 5.0950, Accuracy: 264/5918 (4%)\n",
      "\n",
      "Testing on User 1 watermark:\n",
      "\n",
      "Test set: Average loss: 14.7228, Accuracy: 159/6000 (3%)\n",
      "\n",
      "Testing on User 2 watermark:\n",
      "\n",
      "Test set: Average loss: 0.0003, Accuracy: 6742/6742 (100%)\n",
      "\n",
      "Testing on clean test set\n",
      "\n",
      "Test set: Average loss: 0.0553, Accuracy: 9838/10000 (98%)\n",
      "\n",
      "epoch 4\n",
      "Testing on Users' datasset\n",
      "Testing on User 0 watermark:\n",
      "\n",
      "Test set: Average loss: 4.9800, Accuracy: 369/5918 (6%)\n",
      "\n",
      "Testing on User 1 watermark:\n",
      "\n",
      "Test set: Average loss: 14.8949, Accuracy: 207/6000 (3%)\n",
      "\n",
      "Testing on User 2 watermark:\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 6742/6742 (100%)\n",
      "\n",
      "Testing on clean test set\n",
      "\n",
      "Test set: Average loss: 0.0495, Accuracy: 9852/10000 (99%)\n",
      "\n",
      "epoch 5\n",
      "Testing on Users' datasset\n",
      "Testing on User 0 watermark:\n",
      "\n",
      "Test set: Average loss: 4.4836, Accuracy: 675/5918 (11%)\n",
      "\n",
      "Testing on User 1 watermark:\n",
      "\n",
      "Test set: Average loss: 26.6241, Accuracy: 94/6000 (2%)\n",
      "\n",
      "Testing on User 2 watermark:\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 6742/6742 (100%)\n",
      "\n",
      "Testing on clean test set\n",
      "\n",
      "Test set: Average loss: 0.0935, Accuracy: 9746/10000 (97%)\n",
      "\n",
      "epoch 6\n",
      "Testing on Users' datasset\n",
      "Testing on User 0 watermark:\n",
      "\n",
      "Test set: Average loss: 5.9271, Accuracy: 456/5918 (8%)\n",
      "\n",
      "Testing on User 1 watermark:\n",
      "\n",
      "Test set: Average loss: 9.3137, Accuracy: 274/6000 (5%)\n",
      "\n",
      "Testing on User 2 watermark:\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 6742/6742 (100%)\n",
      "\n",
      "Testing on clean test set\n",
      "\n",
      "Test set: Average loss: 0.0705, Accuracy: 9788/10000 (98%)\n",
      "\n",
      "epoch 7\n",
      "Testing on Users' datasset\n",
      "Testing on User 0 watermark:\n",
      "\n",
      "Test set: Average loss: 5.0600, Accuracy: 458/5918 (8%)\n",
      "\n",
      "Testing on User 1 watermark:\n",
      "\n",
      "Test set: Average loss: 11.2531, Accuracy: 327/6000 (5%)\n",
      "\n",
      "Testing on User 2 watermark:\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 6742/6742 (100%)\n",
      "\n",
      "Testing on clean test set\n",
      "\n",
      "Test set: Average loss: 0.0427, Accuracy: 9882/10000 (99%)\n",
      "\n",
      "epoch 8\n",
      "Testing on Users' datasset\n",
      "Testing on User 0 watermark:\n",
      "\n",
      "Test set: Average loss: 9.0776, Accuracy: 153/5918 (3%)\n",
      "\n",
      "Testing on User 1 watermark:\n",
      "\n",
      "Test set: Average loss: 14.9626, Accuracy: 258/6000 (4%)\n",
      "\n",
      "Testing on User 2 watermark:\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 6742/6742 (100%)\n",
      "\n",
      "Testing on clean test set\n",
      "\n",
      "Test set: Average loss: 0.0402, Accuracy: 9883/10000 (99%)\n",
      "\n",
      "epoch 9\n",
      "Testing on Users' datasset\n",
      "Testing on User 0 watermark:\n",
      "\n",
      "Test set: Average loss: 14.8490, Accuracy: 28/5918 (0%)\n",
      "\n",
      "Testing on User 1 watermark:\n",
      "\n",
      "Test set: Average loss: 10.5945, Accuracy: 509/6000 (8%)\n",
      "\n",
      "Testing on User 2 watermark:\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 6742/6742 (100%)\n",
      "\n",
      "Testing on clean test set\n",
      "\n",
      "Test set: Average loss: 0.0438, Accuracy: 9885/10000 (99%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python moda.py --dataset=\"MNIST\" --num_users=3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the results printed above, before unlearn, all users' watermark have a high accuracy. After unlearn, User0 and User1's watermarks show a low accueacy while the adversary(User2)'s watermark remains high accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results of baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd Baselines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DeepInspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/zcy/MODA_test/MODA/DeepInspect\n",
      "---Trigger Generation---\n",
      "Epoch-0: Loss=331.74, L_trigger=-13.258, L_pert=1724.989, ASR=59.88%\n",
      "Epoch-1: Loss=215.63, L_trigger=-31.364, L_pert=1234.971, ASR=100.0%\n",
      "Epoch-2: Loss=58.401, L_trigger=-36.112, L_pert=472.566, ASR=100.0%\n",
      "Epoch-3: Loss=6.366, L_trigger=-41.96, L_pert=241.631, ASR=100.0%\n",
      "Epoch-4: Loss=-9.514, L_trigger=-44.718, L_pert=176.02, ASR=100.0%\n",
      "Epoch-5: Loss=-16.938, L_trigger=-46.054, L_pert=145.576, ASR=100.0%\n",
      "Epoch-6: Loss=-21.376, L_trigger=-46.697, L_pert=126.605, ASR=100.0%\n",
      "Epoch-7: Loss=-24.301, L_trigger=-47.573, L_pert=116.364, ASR=100.0%\n",
      "Epoch-8: Loss=-26.697, L_trigger=-48.168, L_pert=107.357, ASR=100.0%\n",
      "Epoch-9: Loss=-28.221, L_trigger=-48.739, L_pert=102.591, ASR=100.0%\n",
      "Epoch-10: Loss=-29.472, L_trigger=-49.252, L_pert=98.903, ASR=100.0%\n",
      "Epoch-11: Loss=-30.804, L_trigger=-49.832, L_pert=95.139, ASR=100.0%\n",
      "Epoch-12: Loss=-31.833, L_trigger=-50.428, L_pert=92.976, ASR=100.0%\n",
      "Epoch-13: Loss=-32.682, L_trigger=-50.901, L_pert=91.092, ASR=100.0%\n",
      "Epoch-14: Loss=-33.377, L_trigger=-51.418, L_pert=90.202, ASR=100.0%\n",
      "Epoch-15: Loss=-34.208, L_trigger=-51.789, L_pert=87.906, ASR=100.0%\n",
      "Epoch-16: Loss=-34.793, L_trigger=-52.343, L_pert=87.751, ASR=100.0%\n",
      "Epoch-17: Loss=-35.269, L_trigger=-52.797, L_pert=87.643, ASR=100.0%\n",
      "Epoch-18: Loss=-35.678, L_trigger=-53.104, L_pert=87.131, ASR=100.0%\n",
      "Epoch-19: Loss=-36.174, L_trigger=-53.575, L_pert=87.005, ASR=100.0%\n",
      "Epoch-20: Loss=-36.727, L_trigger=-53.766, L_pert=85.195, ASR=100.0%\n",
      "Epoch-21: Loss=-36.948, L_trigger=-54.199, L_pert=86.25, ASR=100.0%\n",
      "Epoch-22: Loss=-37.317, L_trigger=-54.477, L_pert=85.797, ASR=100.0%\n",
      "Epoch-23: Loss=-37.612, L_trigger=-54.755, L_pert=85.715, ASR=100.0%\n",
      "Epoch-24: Loss=-38.029, L_trigger=-55.034, L_pert=85.025, ASR=100.0%\n",
      "Epoch-25: Loss=-38.196, L_trigger=-55.343, L_pert=85.738, ASR=100.0%\n",
      "Epoch-26: Loss=-38.492, L_trigger=-55.565, L_pert=85.362, ASR=100.0%\n",
      "Epoch-27: Loss=-38.81, L_trigger=-55.661, L_pert=84.255, ASR=100.0%\n",
      "Epoch-28: Loss=-39.112, L_trigger=-55.964, L_pert=84.264, ASR=100.0%\n",
      "Epoch-29: Loss=-39.384, L_trigger=-56.06, L_pert=83.377, ASR=100.0%\n",
      "---Model Patching---\n",
      "Before Cleanse. Clean Acc:99.98%, ASR:100.0%\n",
      "Epoch-0. Clean Acc:97.97%, ASR:0.33%\n",
      "Epoch-1. Clean Acc:99.35%, ASR:0.15%\n",
      "Epoch-2. Clean Acc:99.41%, ASR:0.15%\n",
      "Epoch-3. Clean Acc:99.5%, ASR:0.15%\n",
      "Epoch-4. Clean Acc:99.53%, ASR:0.15%\n",
      "Epoch-5. Clean Acc:99.54%, ASR:0.15%\n",
      "Epoch-6. Clean Acc:99.53%, ASR:0.15%\n",
      "Epoch-7. Clean Acc:99.53%, ASR:0.13%\n",
      "Epoch-8. Clean Acc:99.59%, ASR:0.13%\n",
      "Epoch-9. Clean Acc:99.6%, ASR:0.13%\n",
      "After Cleanse. Clean Acc:99.6%, ASR:0.13%, Backdoor(Watermark) Removal Rate:99.87%.\n"
     ]
    }
   ],
   "source": [
    "# DI\n",
    "%cd DeepInspect\n",
    "!python main.py -dataset=mnist \n",
    "# !python main.py -dataset=gtsrb -clean_budget=5000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Cleanse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/zcy/MODA_test/MODA/backdoor-toolbox\n",
      "[Generate Clean Split] Save clean_set/mnist/clean_split/data/0.png\n",
      "......\n",
      "[Generate Test Set] Save clean_set/mnist/test_split/data/7999.png\n",
      "[Generate Test Set] Save clean_set/mnist/test_split/labels\n",
      "[target class : 0]\n",
      "Poisoned set directory 'poisoned_train_set/mnist/badnet_0.010_poison_seed=0' to be created is not empty! Exiting...\n",
      "dataset : poisoned_train_set/mnist/badnet_0.010_poison_seed=0/imgs\n",
      "Will save to 'poisoned_train_set/mnist/badnet_0.010_poison_seed=0/full_base_no_aug_seed=2333.pt'.\n",
      "Model 'poisoned_train_set/mnist/badnet_0.010_poison_seed=0/full_base_no_aug_seed=2333.pt' already exists!\n",
      "<Backdoor Training> Train Epoch: 1 \tLoss: 0.316521, lr: 0.100000, Time: 3.87s\n",
      "100%|███████████████████████████████████████████| 63/63 [00:01<00:00, 33.39it/s]\n",
      "Clean ACC: 7392/8000 = 0.924000, Loss: 0.22779200971126556\n",
      "ASR: 11/7214 = 0.001525\n",
      "\n",
      "\n",
      "<Backdoor Training> Train Epoch: 2 \tLoss: 0.823712, lr: 0.100000, Time: 2.67s\n",
      "100%|███████████████████████████████████████████| 63/63 [00:01<00:00, 32.88it/s]\n",
      "Clean ACC: 7556/8000 = 0.944500, Loss: 0.22825981676578522\n",
      "ASR: 95/7214 = 0.013169\n",
      "\n",
      "\n",
      "<Backdoor Training> Train Epoch: 3 \tLoss: 0.281630, lr: 0.100000, Time: 2.68s\n",
      "100%|███████████████████████████████████████████| 63/63 [00:01<00:00, 33.15it/s]\n",
      "Clean ACC: 7421/8000 = 0.927625, Loss: 0.23551048338413239\n",
      "ASR: 4/7214 = 0.000554\n",
      "\n",
      "\n",
      "<Backdoor Training> Train Epoch: 4 \tLoss: 0.066480, lr: 0.100000, Time: 2.68s\n",
      "100%|███████████████████████████████████████████| 63/63 [00:01<00:00, 32.71it/s]\n",
      "Clean ACC: 7858/8000 = 0.982250, Loss: 0.06914760917425156\n",
      "ASR: 30/7214 = 0.004159\n",
      "\n",
      "\n",
      "<Backdoor Training> Train Epoch: 5 \tLoss: 0.027262, lr: 0.100000, Time: 2.67s\n",
      "100%|███████████████████████████████████████████| 63/63 [00:01<00:00, 32.75it/s]\n",
      "Clean ACC: 7913/8000 = 0.989125, Loss: 0.03985161706805229\n",
      "ASR: 6/7214 = 0.000832\n",
      "\n",
      "\n",
      "<Backdoor Training> Train Epoch: 6 \tLoss: 0.009672, lr: 0.100000, Time: 2.66s\n",
      "100%|███████████████████████████████████████████| 63/63 [00:01<00:00, 32.61it/s]\n",
      "Clean ACC: 7933/8000 = 0.991625, Loss: 0.03570976480841637\n",
      "ASR: 31/7214 = 0.004297\n",
      "\n",
      "\n",
      "<Backdoor Training> Train Epoch: 7 \tLoss: 0.159421, lr: 0.100000, Time: 2.66s\n",
      "100%|███████████████████████████████████████████| 63/63 [00:01<00:00, 32.76it/s]\n",
      "Clean ACC: 7927/8000 = 0.990875, Loss: 0.03291728347539902\n",
      "ASR: 2354/7214 = 0.326310\n",
      "\n",
      "\n",
      "<Backdoor Training> Train Epoch: 8 \tLoss: 0.013098, lr: 0.100000, Time: 2.67s\n",
      "100%|███████████████████████████████████████████| 63/63 [00:01<00:00, 32.47it/s]\n",
      "Clean ACC: 7969/8000 = 0.996125, Loss: 0.01361782941967249\n",
      "ASR: 6269/7214 = 0.869005\n",
      "\n",
      "\n",
      "<Backdoor Training> Train Epoch: 9 \tLoss: 0.174594, lr: 0.100000, Time: 2.68s\n",
      "100%|███████████████████████████████████████████| 63/63 [00:01<00:00, 32.40it/s]\n",
      "Clean ACC: 7956/8000 = 0.994500, Loss: 0.016099005937576294\n",
      "ASR: 6604/7214 = 0.915442\n",
      "\n",
      "\n",
      "<Backdoor Training> Train Epoch: 10 \tLoss: 0.002262, lr: 0.100000, Time: 2.66s\n",
      "100%|███████████████████████████████████████████| 63/63 [00:01<00:00, 32.66it/s]\n",
      "Clean ACC: 7958/8000 = 0.994750, Loss: 0.015324190258979797\n",
      "ASR: 7073/7214 = 0.980455\n",
      "\n",
      "\n",
      "<Backdoor Training> Train Epoch: 11 \tLoss: 0.000787, lr: 0.010000, Time: 2.66s\n",
      "100%|███████████████████████████████████████████| 63/63 [00:01<00:00, 32.39it/s]\n",
      "Clean ACC: 7999/8000 = 0.999875, Loss: 0.002654772251844406\n",
      "ASR: 7050/7214 = 0.977266\n",
      "\n",
      "\n",
      "<Backdoor Training> Train Epoch: 12 \tLoss: 0.005538, lr: 0.010000, Time: 2.67s\n",
      "100%|███████████████████████████████████████████| 63/63 [00:01<00:00, 32.39it/s]\n",
      "Clean ACC: 7999/8000 = 0.999875, Loss: 0.0020483671687543392\n",
      "ASR: 7010/7214 = 0.971722\n",
      "\n",
      "\n",
      "<Backdoor Training> Train Epoch: 13 \tLoss: 0.028186, lr: 0.010000, Time: 2.66s\n",
      "100%|███████████████████████████████████████████| 63/63 [00:01<00:00, 32.55it/s]\n",
      "Clean ACC: 8000/8000 = 1.000000, Loss: 0.0017676050774753094\n",
      "ASR: 7046/7214 = 0.976712\n",
      "\n",
      "\n",
      "<Backdoor Training> Train Epoch: 14 \tLoss: 0.008352, lr: 0.010000, Time: 2.67s\n",
      "100%|███████████████████████████████████████████| 63/63 [00:01<00:00, 32.64it/s]\n",
      "Clean ACC: 8000/8000 = 1.000000, Loss: 0.0014363081427291036\n",
      "ASR: 7021/7214 = 0.973246\n",
      "\n",
      "\n",
      "<Backdoor Training> Train Epoch: 15 \tLoss: 0.000969, lr: 0.010000, Time: 2.66s\n",
      "100%|███████████████████████████████████████████| 63/63 [00:01<00:00, 32.50it/s]\n",
      "Clean ACC: 8000/8000 = 1.000000, Loss: 0.0012447519693523645\n",
      "ASR: 6973/7214 = 0.966593\n",
      "\n",
      "\n",
      "<Backdoor Training> Train Epoch: 16 \tLoss: 0.001604, lr: 0.001000, Time: 2.69s\n",
      "100%|███████████████████████████████████████████| 63/63 [00:01<00:00, 32.32it/s]\n",
      "Clean ACC: 8000/8000 = 1.000000, Loss: 0.0012888172641396523\n",
      "ASR: 6982/7214 = 0.967840\n",
      "\n",
      "\n",
      "<Backdoor Training> Train Epoch: 17 \tLoss: 0.000047, lr: 0.001000, Time: 2.67s\n",
      "100%|███████████████████████████████████████████| 63/63 [00:01<00:00, 32.52it/s]\n",
      "Clean ACC: 8000/8000 = 1.000000, Loss: 0.0012550122337415814\n",
      "ASR: 6972/7214 = 0.966454\n",
      "\n",
      "\n",
      "<Backdoor Training> Train Epoch: 18 \tLoss: 0.007203, lr: 0.001000, Time: 2.66s\n",
      "100%|███████████████████████████████████████████| 63/63 [00:01<00:00, 32.38it/s]\n",
      "Clean ACC: 8000/8000 = 1.000000, Loss: 0.0013581009116023779\n",
      "ASR: 6947/7214 = 0.962989\n",
      "\n",
      "\n",
      "<Backdoor Training> Train Epoch: 19 \tLoss: 0.000061, lr: 0.001000, Time: 2.68s\n",
      "100%|███████████████████████████████████████████| 63/63 [00:01<00:00, 32.74it/s]\n",
      "Clean ACC: 8000/8000 = 1.000000, Loss: 0.001216729055158794\n",
      "ASR: 7013/7214 = 0.972138\n",
      "\n",
      "\n",
      "<Backdoor Training> Train Epoch: 20 \tLoss: 0.001172, lr: 0.001000, Time: 2.67s\n",
      "100%|███████████████████████████████████████████| 63/63 [00:01<00:00, 32.35it/s]\n",
      "Clean ACC: 8000/8000 = 1.000000, Loss: 0.0013349521905183792\n",
      "ASR: 6969/7214 = 0.966038\n",
      "\n",
      "\n",
      "Evaluating model 'poisoned_train_set/mnist/badnet_0.010_poison_seed=0/full_base_no_aug_seed=2333.pt'...\n",
      "100%|███████████████████████████████████████████| 63/63 [00:03<00:00, 20.80it/s]\n",
      "Clean ACC: 8000/8000 = 1.000000, Loss: 0.0013349521905183792\n",
      "ASR: 6969/7214 = 0.966038\n",
      "\n",
      "trigger_path: ./triggers/badnet_patch_32.png\n",
      "trigger_mask_path: ./triggers/mask_badnet_patch_32.png\n",
      "Evaluating model 'poisoned_train_set/mnist/badnet_0.010_poison_seed=0/full_base_no_aug_seed=2333.pt'...\n",
      "Class: 1/10\n",
      "Epoch: 1/30 Loss: 0.1032,        Acc: 0.9995,         Norm: 101.1664,      Entropy: 0.0021,     Time: 0:00:03,      \n",
      "Epoch: 2/30 Loss: 0.0119,        Acc: 0.9990,         Norm: 8.9667,        Entropy: 0.0030,     Time: 0:00:02,      \n",
      "Epoch: 3/30 Loss: 0.0101,        Acc: 0.9985,         Norm: 7.2441,        Entropy: 0.0029,     Time: 0:00:02,      \n",
      "Epoch: 4/30 Loss: 0.0091,        Acc: 0.9990,         Norm: 7.0959,        Entropy: 0.0020,     Time: 0:00:02,      \n",
      "Epoch: 5/30 Loss: 0.0090,        Acc: 0.9985,         Norm: 6.7273,        Entropy: 0.0023,     Time: 0:00:02,      \n",
      "up cost from 0.0010 to 0.0015\n",
      "Epoch: 6/30 Loss: 0.0133,        Acc: 0.9980,         Norm: 6.3487,        Entropy: 0.0038,     Time: 0:00:02,      \n",
      "Epoch: 7/30 Loss: 0.0125,        Acc: 0.9985,         Norm: 6.4553,        Entropy: 0.0028,     Time: 0:00:02,      \n",
      "Epoch: 8/30 Loss: 0.0123,        Acc: 0.9990,         Norm: 6.4154,        Entropy: 0.0027,     Time: 0:00:02,      \n",
      "Epoch: 9/30 Loss: 0.0127,        Acc: 0.9980,         Norm: 6.4172,        Entropy: 0.0030,     Time: 0:00:02,      \n",
      "Epoch: 10/30 Loss: 0.0127,        Acc: 0.9980,         Norm: 6.1277,        Entropy: 0.0035,     Time: 0:00:02,      \n",
      "up cost from 0.0015 to 0.0023\n",
      "Epoch: 11/30 Loss: 0.0170,        Acc: 0.9985,         Norm: 6.0919,        Entropy: 0.0032,     Time: 0:00:02,      \n",
      "Epoch: 12/30 Loss: 0.0173,        Acc: 0.9980,         Norm: 5.8951,        Entropy: 0.0040,     Time: 0:00:02,      \n",
      "Epoch: 13/30 Loss: 0.0170,        Acc: 0.9980,         Norm: 6.1229,        Entropy: 0.0032,     Time: 0:00:02,      \n",
      "Epoch: 14/30 Loss: 0.0168,        Acc: 0.9980,         Norm: 5.6529,        Entropy: 0.0041,     Time: 0:00:02,      \n",
      "Epoch: 15/30 Loss: 0.0172,        Acc: 0.9980,         Norm: 6.0702,        Entropy: 0.0036,     Time: 0:00:02,      \n",
      "up cost from 0.0023 to 0.0034\n",
      "Epoch: 16/30 Loss: 0.0244,        Acc: 0.9975,         Norm: 5.5387,        Entropy: 0.0057,     Time: 0:00:02,      \n",
      "Epoch: 17/30 Loss: 0.0239,        Acc: 0.9970,         Norm: 5.4339,        Entropy: 0.0056,     Time: 0:00:02,      \n",
      "Epoch: 18/30 Loss: 0.0237,        Acc: 0.9980,         Norm: 5.7876,        Entropy: 0.0041,     Time: 0:00:02,      \n",
      "Epoch: 19/30 Loss: 0.0237,        Acc: 0.9980,         Norm: 5.6228,        Entropy: 0.0048,     Time: 0:00:02,      \n",
      "Epoch: 20/30 Loss: 0.0241,        Acc: 0.9970,         Norm: 5.4917,        Entropy: 0.0055,     Time: 0:00:02,      \n",
      "up cost from 0.0034 to 0.0051\n",
      "Epoch: 21/30 Loss: 0.0327,        Acc: 0.9980,         Norm: 5.4439,        Entropy: 0.0051,     Time: 0:00:02,      \n",
      "Epoch: 22/30 Loss: 0.0328,        Acc: 0.9970,         Norm: 5.1619,        Entropy: 0.0067,     Time: 0:00:02,      \n",
      "Epoch: 23/30 Loss: 0.0331,        Acc: 0.9975,         Norm: 5.4515,        Entropy: 0.0055,     Time: 0:00:02,      \n",
      "Epoch: 24/30 Loss: 0.0332,        Acc: 0.9970,         Norm: 4.7799,        Entropy: 0.0090,     Time: 0:00:02,      \n",
      "Epoch: 25/30 Loss: 0.0307,        Acc: 0.9975,         Norm: 4.7305,        Entropy: 0.0067,     Time: 0:00:02,      \n",
      "up cost from 0.0051 to 0.0076\n",
      "Epoch: 26/30 Loss: 0.0435,        Acc: 0.9960,         Norm: 4.3977,        Entropy: 0.0101,     Time: 0:00:02,      \n",
      "Epoch: 27/30 Loss: 0.0446,        Acc: 0.9955,         Norm: 4.3772,        Entropy: 0.0114,     Time: 0:00:02,      \n",
      "Epoch: 28/30 Loss: 0.0427,        Acc: 0.9970,         Norm: 4.5110,        Entropy: 0.0085,     Time: 0:00:02,      \n",
      "Epoch: 29/30 Loss: 0.0427,        Acc: 0.9970,         Norm: 4.4719,        Entropy: 0.0087,     Time: 0:00:02,      \n",
      "Epoch: 30/30 Loss: 0.0423,        Acc: 0.9970,         Norm: 4.4816,        Entropy: 0.0083,     Time: 0:00:02,      \n",
      "up cost from 0.0076 to 0.0114\n",
      "Defense results saved at: other_defenses_tool_box/results/NC/neural_cleanse_mnist_badnet_0.010_full_base_no_aug_seed=2333.pt_poison_seed=0.npz\n",
      "Restored trigger mark of class 0 saved at: other_defenses_tool_box/results/NC/mark_neural_cleanse_class=0_mnist_badnet_0.010_full_base_no_aug_seed=2333.pt_poison_seed=0.png\n",
      "Restored trigger mask of class 0 saved at: other_defenses_tool_box/results/NC/mask_neural_cleanse_class=0_mnist_badnet_0.010_full_base_no_aug_seed=2333.pt_poison_seed=0.png\n",
      "Restored trigger of class 0 saved at: other_defenses_tool_box/results/NC/trigger_neural_cleanse_class=0_mnist_badnet_0.010_full_base_no_aug_seed=2333.pt_poison_seed=0.png\n",
      "\n",
      "mask norms:  tensor([3.7982], device='cuda:0')\n",
      "mask anomaly indices:  tensor([nan], device='cuda:0')\n",
      "loss:  tensor([0.0083])\n",
      "loss anomaly indices:  tensor([nan])\n",
      "<Oracle> Unlearning with reversed trigger from class 0\n",
      "torch.Size([3, 32, 32]) torch.Size([32, 32])\n",
      "full_train: 60000\n",
      "train_size: 6000 drop_size: 54000\n",
      "Poison num: 1200\n",
      "6000\n",
      "Accuracy: 8000/8000 = 1.000000\n",
      "ASR: 6970/7214 = 0.966177\n",
      "ACR (Attack Correct Rate): 1026/8000 = 0.128250\n",
      "100%|███████████████████████████████████████████| 47/47 [00:02<00:00, 16.08it/s]\n",
      "\n",
      "<Unlearning> Train Epoch: 0 \tLoss: 0.124743, Train Acc: 0.965833, lr: 0.01\n",
      "Accuracy: 7966/8000 = 0.995750\n",
      "ASR: 7/7214 = 0.000970\n",
      "ACR (Attack Correct Rate): 7950/8000 = 0.993750\n",
      "Saved repaired model to poisoned_train_set/mnist/badnet_0.010_poison_seed=0/defended_NC_full_base_no_aug_seed=2333.pt\n",
      "Elapsed time: 74.69s\n"
     ]
    }
   ],
   "source": [
    "# NC\n",
    "%cd ../backdoor-toolbox\n",
    "# ---------------------------------------------------------------------------------------------------\n",
    "# MNIST\n",
    "# Create a clean set\n",
    "!python create_clean_set.py -dataset=mnist\n",
    "\n",
    "# Create a poisoned training set\n",
    "!python create_poisoned_set.py -dataset=mnist -poison_type=badnet -poison_rate=0.01\n",
    "\n",
    "# Train on the poisoned training set\n",
    "!python train_on_poisoned_set.py -dataset=mnist -poison_type=badnet -poison_rate=0.01 -no_aug\n",
    "\n",
    "# Test the backdoor model (optional)\n",
    "!python test_model.py -dataset=mnist -poison_type=badnet -poison_rate=0.01 -no_aug\n",
    "\n",
    "# Defenses (NC)\n",
    "!python other_defense.py -defense=NC -dataset=mnist -poison_type=badnet -poison_rate=0.01 -no_aug\n",
    "\n",
    "# As shown in the result below, Backdoor(Watermark) Removal Rate = (0.966177-0.000970)*100% = 96.52%\n",
    "\n",
    "# ---------------------------------------------------------------------------------------------------\n",
    "# GTSRB\n",
    "# # Create a clean set\n",
    "# !python create_clean_set.py -dataset=gtsrb -clean_budget=5000\n",
    "\n",
    "# # Create a poisoned training set\n",
    "# !python create_poisoned_set.py -dataset=gtsrb -poison_type=badnet -poison_rate=0.01\n",
    "\n",
    "# # Train on the poisoned training set\n",
    "# !python train_on_poisoned_set.py -dataset=gtsrb -poison_type=badnet -poison_rate=0.01\n",
    "\n",
    "# # Test the backdoor model (optional)\n",
    "# !python test_model.py -dataset=gtsrb -poison_type=badnet -poison_rate=0.01\n",
    "\n",
    "# # Defenses (NC)\n",
    "# !python other_defense.py -defense=NC -dataset=gtsrb -poison_type=badnet -poison_rate=0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WAFFLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/zcy/MODA_test/MODA/WAFFLE\n",
      "Figure(640x480)\n",
      "Figure(640x480)\n",
      "-- Pretrain  1 -- | Accuracy of model in test set is: 0.100000\n",
      "-- Pretrain  2 -- | Accuracy of model in test set is: 0.100000\n",
      "-- Pretrain  3 -- | Accuracy of model in test set is: 0.100000\n",
      "-- Pretrain  4 -- | Accuracy of model in test set is: 0.100000\n",
      "-- Pretrain  5 -- | Accuracy of model in test set is: 0.190000\n",
      "-- Pretrain  6 -- | Accuracy of model in test set is: 0.180000\n",
      "-- Pretrain  7 -- | Accuracy of model in test set is: 0.120000\n",
      "-- Pretrain  8 -- | Accuracy of model in test set is: 0.180000\n",
      "-- Pretrain  9 -- | Accuracy of model in test set is: 0.470000\n",
      "-- Pretrain 10 -- | Accuracy of model in test set is: 0.810000\n",
      "-- Pretrain 11 -- | Accuracy of model in test set is: 0.670000\n",
      "-- Pretrain 12 -- | Accuracy of model in test set is: 0.930000\n",
      "-- Pretrain 13 -- | Accuracy of model in test set is: 0.970000\n",
      "-- Pretrain 14 -- | Accuracy of model in test set is: 1.000000\n",
      "-- Pretrain 15 -- | Accuracy of model in test set is: 0.880000\n",
      "-- Pretrain 16 -- | Accuracy of model in test set is: 0.970000\n",
      "-- Pretrain 17 -- | Accuracy of model in test set is: 0.920000\n",
      "-- Pretrain 18 -- | Accuracy of model in test set is: 0.930000\n",
      "-- Pretrain 19 -- | Accuracy of model in test set is: 0.910000\n",
      "-- Pretrain 20 -- | Accuracy of model in test set is: 0.730000\n",
      "-- Pretrain 21 -- | Accuracy of model in test set is: 0.520000\n",
      "-- Pretrain 22 -- | Accuracy of model in test set is: 0.980000\n",
      "-- Pretrain 23 -- | Accuracy of model in test set is: 0.990000\n",
      "-- Pretrain 24 -- | Accuracy of model in test set is: 0.770000\n",
      "-- Pretrain 25 -- | Accuracy of model in test set is: 0.700000\n",
      "-- Round  1 -- | Accuracy of model in test set is: 0.978200\n",
      "-- Retain  1- 1 -- | Accuracy of model in test set is: 0.490000\n",
      "-- Retain  1- 2 -- | Accuracy of model in test set is: 0.730000\n",
      "-- Retain  1- 3 -- | Accuracy of model in test set is: 0.890000\n",
      "-- Retain  1- 4 -- | Accuracy of model in test set is: 0.950000\n",
      "-- Retain  1- 5 -- | Accuracy of model in test set is: 0.980000\n",
      "Accuracy of model in test set is: 0.978000\n",
      "-- Round  2 -- | Accuracy of model in test set is: 0.987100\n",
      "-- Retain  2- 1 -- | Accuracy of model in test set is: 0.570000\n",
      "-- Retain  2- 2 -- | Accuracy of model in test set is: 0.890000\n",
      "-- Retain  2- 3 -- | Accuracy of model in test set is: 0.950000\n",
      "-- Retain  2- 4 -- | Accuracy of model in test set is: 0.980000\n",
      "Accuracy of model in test set is: 0.986300\n",
      "-- Round  3 -- | Accuracy of model in test set is: 0.988000\n",
      "-- Retain  3- 1 -- | Accuracy of model in test set is: 0.660000\n",
      "-- Retain  3- 2 -- | Accuracy of model in test set is: 0.890000\n",
      "-- Retain  3- 3 -- | Accuracy of model in test set is: 0.950000\n",
      "-- Retain  3- 4 -- | Accuracy of model in test set is: 1.000000\n",
      "Accuracy of model in test set is: 0.987600\n",
      "-- Round  4 -- | Accuracy of model in test set is: 0.988800\n",
      "-- Retain  4- 1 -- | Accuracy of model in test set is: 0.610000\n",
      "-- Retain  4- 2 -- | Accuracy of model in test set is: 0.880000\n",
      "-- Retain  4- 3 -- | Accuracy of model in test set is: 0.970000\n",
      "-- Retain  4- 4 -- | Accuracy of model in test set is: 1.000000\n",
      "Accuracy of model in test set is: 0.988000\n",
      "-- Round  5 -- | Accuracy of model in test set is: 0.989600\n",
      "-- Retain  5- 1 -- | Accuracy of model in test set is: 0.750000\n",
      "-- Retain  5- 2 -- | Accuracy of model in test set is: 0.800000\n",
      "-- Retain  5- 3 -- | Accuracy of model in test set is: 0.960000\n",
      "-- Retain  5- 4 -- | Accuracy of model in test set is: 0.990000\n",
      "Accuracy of model in test set is: 0.988900\n",
      "-- Round  6 -- | Accuracy of model in test set is: 0.989600\n",
      "-- Retain  6- 1 -- | Accuracy of model in test set is: 0.580000\n",
      "-- Retain  6- 2 -- | Accuracy of model in test set is: 0.860000\n",
      "-- Retain  6- 3 -- | Accuracy of model in test set is: 0.970000\n",
      "-- Retain  6- 4 -- | Accuracy of model in test set is: 1.000000\n",
      "Accuracy of model in test set is: 0.989100\n",
      "-- Round  7 -- | Accuracy of model in test set is: 0.990200\n",
      "-- Retain  7- 1 -- | Accuracy of model in test set is: 0.630000\n",
      "-- Retain  7- 2 -- | Accuracy of model in test set is: 0.930000\n",
      "-- Retain  7- 3 -- | Accuracy of model in test set is: 0.970000\n",
      "-- Retain  7- 4 -- | Accuracy of model in test set is: 0.990000\n",
      "Accuracy of model in test set is: 0.989800\n",
      "-- Round  8 -- | Accuracy of model in test set is: 0.989900\n",
      "-- Retain  8- 1 -- | Accuracy of model in test set is: 0.580000\n",
      "-- Retain  8- 2 -- | Accuracy of model in test set is: 0.920000\n",
      "-- Retain  8- 3 -- | Accuracy of model in test set is: 0.950000\n",
      "-- Retain  8- 4 -- | Accuracy of model in test set is: 0.990000\n",
      "Accuracy of model in test set is: 0.989100\n",
      "-- Round  9 -- | Accuracy of model in test set is: 0.990600\n",
      "-- Retain  9- 1 -- | Accuracy of model in test set is: 0.720000\n",
      "-- Retain  9- 2 -- | Accuracy of model in test set is: 0.910000\n",
      "-- Retain  9- 3 -- | Accuracy of model in test set is: 0.980000\n",
      "Accuracy of model in test set is: 0.989900\n",
      "-- Round 10 -- | Accuracy of model in test set is: 0.991300\n",
      "-- Retain 10- 1 -- | Accuracy of model in test set is: 0.480000\n",
      "-- Retain 10- 2 -- | Accuracy of model in test set is: 0.910000\n",
      "-- Retain 10- 3 -- | Accuracy of model in test set is: 0.960000\n",
      "-- Retain 10- 4 -- | Accuracy of model in test set is: 0.990000\n",
      "Accuracy of model in test set is: 0.989700\n",
      "-- Round 11 -- | Accuracy of model in test set is: 0.991000\n",
      "-- Retain 11- 1 -- | Accuracy of model in test set is: 0.650000\n",
      "-- Retain 11- 2 -- | Accuracy of model in test set is: 0.900000\n",
      "-- Retain 11- 3 -- | Accuracy of model in test set is: 0.990000\n",
      "Accuracy of model in test set is: 0.989900\n",
      "-- Round 12 -- | Accuracy of model in test set is: 0.990900\n",
      "-- Retain 12- 1 -- | Accuracy of model in test set is: 0.700000\n",
      "-- Retain 12- 2 -- | Accuracy of model in test set is: 0.900000\n",
      "-- Retain 12- 3 -- | Accuracy of model in test set is: 0.960000\n",
      "-- Retain 12- 4 -- | Accuracy of model in test set is: 1.000000\n",
      "Accuracy of model in test set is: 0.989600\n",
      "-- Round 13 -- | Accuracy of model in test set is: 0.991500\n",
      "-- Retain 13- 1 -- | Accuracy of model in test set is: 0.650000\n",
      "-- Retain 13- 2 -- | Accuracy of model in test set is: 0.920000\n",
      "-- Retain 13- 3 -- | Accuracy of model in test set is: 0.970000\n",
      "-- Retain 13- 4 -- | Accuracy of model in test set is: 0.990000\n",
      "Accuracy of model in test set is: 0.989900\n",
      "-- Round 14 -- | Accuracy of model in test set is: 0.990600\n",
      "-- Retain 14- 1 -- | Accuracy of model in test set is: 0.680000\n",
      "-- Retain 14- 2 -- | Accuracy of model in test set is: 0.910000\n",
      "-- Retain 14- 3 -- | Accuracy of model in test set is: 0.970000\n",
      "-- Retain 14- 4 -- | Accuracy of model in test set is: 0.990000\n",
      "Accuracy of model in test set is: 0.990200\n",
      "-- Round 15 -- | Accuracy of model in test set is: 0.991100\n",
      "-- Retain 15- 1 -- | Accuracy of model in test set is: 0.640000\n",
      "-- Retain 15- 2 -- | Accuracy of model in test set is: 0.930000\n",
      "-- Retain 15- 3 -- | Accuracy of model in test set is: 0.980000\n",
      "Accuracy of model in test set is: 0.989800\n",
      "-- Round 16 -- | Accuracy of model in test set is: 0.990500\n",
      "-- Retain 16- 1 -- | Accuracy of model in test set is: 0.650000\n",
      "-- Retain 16- 2 -- | Accuracy of model in test set is: 0.900000\n",
      "-- Retain 16- 3 -- | Accuracy of model in test set is: 0.960000\n",
      "-- Retain 16- 4 -- | Accuracy of model in test set is: 0.990000\n",
      "Accuracy of model in test set is: 0.989900\n",
      "-- Round 17 -- | Accuracy of model in test set is: 0.990900\n",
      "-- Retain 17- 1 -- | Accuracy of model in test set is: 0.620000\n",
      "-- Retain 17- 2 -- | Accuracy of model in test set is: 0.910000\n",
      "-- Retain 17- 3 -- | Accuracy of model in test set is: 0.990000\n",
      "Accuracy of model in test set is: 0.990300\n",
      "-- Round 18 -- | Accuracy of model in test set is: 0.991100\n",
      "-- Retain 18- 1 -- | Accuracy of model in test set is: 0.740000\n",
      "-- Retain 18- 2 -- | Accuracy of model in test set is: 0.930000\n",
      "-- Retain 18- 3 -- | Accuracy of model in test set is: 0.970000\n",
      "-- Retain 18- 4 -- | Accuracy of model in test set is: 0.980000\n",
      "Accuracy of model in test set is: 0.989900\n",
      "-- Round 19 -- | Accuracy of model in test set is: 0.990900\n",
      "-- Retain 19- 1 -- | Accuracy of model in test set is: 0.700000\n",
      "-- Retain 19- 2 -- | Accuracy of model in test set is: 0.930000\n",
      "-- Retain 19- 3 -- | Accuracy of model in test set is: 0.960000\n",
      "-- Retain 19- 4 -- | Accuracy of model in test set is: 0.990000\n",
      "Accuracy of model in test set is: 0.990100\n",
      "-- Round 20 -- | Accuracy of model in test set is: 0.990900\n",
      "-- Retain 20- 1 -- | Accuracy of model in test set is: 0.670000\n",
      "-- Retain 20- 2 -- | Accuracy of model in test set is: 0.920000\n",
      "-- Retain 20- 3 -- | Accuracy of model in test set is: 0.990000\n",
      "Accuracy of model in test set is: 0.990300\n",
      "-- Task Acc --\n",
      "Accuracy of model in test set is: 0.990300\n",
      "-- WaterMark Acc --\n",
      "Accuracy of model in test set is: 0.990000\n"
     ]
    }
   ],
   "source": [
    "# WAFFLE\n",
    "%cd ../WAFFLE\n",
    "# !python WAFFLE-MNIST_nclients.py --clients=2 --rounds=20\n",
    "# !python WAFFLE-MNIST_nclients.py --clients=3 --rounds=20\n",
    "!python WAFFLE-MNIST_nclients.py --clients=6 --rounds=20\n",
    "# !python WAFFLE-CIFAR10_nclients.py --clients=2 --rounds=20\n",
    "# !python WAFFLE-CIFAR10_nclients.py --clients=3 --rounds=20\n",
    "# !python WAFFLE-CIFAR10_nclients.py --clients=6 --rounds=20"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyaudio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
