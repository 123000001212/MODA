{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from itertools import cycle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torchsummary import summary\n",
    "from numpy.random import randint\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from model_init import *\n",
    "from dataset_init import *\n",
    "from utils.others import *\n",
    "from utils.testModel import *\n",
    "import time\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imShow(img):\n",
    "    img = img /2 + 0.5\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1,2,0)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An example of MNIST and 3 users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST wm 3 users\n",
    "# 6 -> 8\n",
    "# unrelated -> 7\n",
    "# noise -> 9 (adv)\n",
    "dataTransform = transforms.Compose([\n",
    "                            transforms.CenterCrop(32),\n",
    "                            transforms.Resize((32,32)),\n",
    "                            transforms.ToTensor(),\n",
    "                            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "                        ])\n",
    "oridataset=datasets.ImageFolder('./wm_MNIST',transform=dataTransform)\n",
    "\n",
    "# user 1 (unrelated): correct label to 0\n",
    "wmdata=[]\n",
    "for data,i in oridataset:\n",
    "    if i==0:\n",
    "        wmdata.append((data,0))\n",
    "\n",
    "wmdataset=myDataset(wmdata)\n",
    "torch.save(wmdataset,\"./inversed_wm_data/MNIST/unlearn_unrelated.pth\")\n",
    "\n",
    "# user 0 (trigger): correct label to 6\n",
    "wmdata=[]\n",
    "for data,i in oridataset:\n",
    "    if i==1:\n",
    "        wmdata.append((data,6))\n",
    "\n",
    "wmdataset=myDataset(wmdata)\n",
    "torch.save(wmdataset,\"./inversed_wm_data/MNIST/unlearn_trigger.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For other settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST wm\n",
    "# 0 -> 9\n",
    "# 1 -> 8\n",
    "# 2 -> 7\n",
    "# 3 -> 6\n",
    "# unrelated -> 5\n",
    "# noise -> 4 (adv)\n",
    "dataTransform = transforms.Compose([\n",
    "                            transforms.CenterCrop(32),\n",
    "                            transforms.Resize((32,32)),\n",
    "                            transforms.ToTensor(),\n",
    "                            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "                        ])\n",
    "oridataset=datasets.ImageFolder('./wm_MNIST',transform=dataTransform)\n",
    "wmdata=[]\n",
    "for data,i in oridataset:\n",
    "    if i==0:\n",
    "        #print('label',i)\n",
    "        #imShow(torchvision.utils.make_grid(data))\n",
    "        #break\n",
    "        wmdata.append((data,0))\n",
    "\n",
    "wmdataset=myDataset(wmdata)\n",
    "torch.save(wmdataset,\"./inversed_wm_data/MNIST_6/user5.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GTSRB wm\n",
    "# 1 -> 33\n",
    "# 2 -> 34\n",
    "# 13 -> 35\n",
    "# 24 -> 36\n",
    "# unrelated -> 38\n",
    "# noise -> 9 (adv)\n",
    "dataTransform = transforms.Compose([\n",
    "                            transforms.CenterCrop(32),\n",
    "                            transforms.Resize((32,32)),\n",
    "                            transforms.ToTensor(),\n",
    "                            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "                        ])\n",
    "oridataset=datasets.ImageFolder('./wm_GTSRB',transform=dataTransform)\n",
    "wmdata=[]\n",
    "for data,i in oridataset:\n",
    "    if i==4:\n",
    "        #print('label',i)\n",
    "        #imShow(torchvision.utils.make_grid(data))\n",
    "        #break\n",
    "        wmdata.append((data,15))\n",
    "\n",
    "wmdataset=myDataset(wmdata)\n",
    "torch.save(wmdataset,\"./inversed_wm_data/GTSRB_6/user5.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FashionMNIST wm\n",
    "# 4 -> 8\n",
    "# 1 -> 6\n",
    "# 0 -> 5\n",
    "# 2 -> 4\n",
    "# unrelated -> 7\n",
    "# noise -> 9 (adv)\n",
    "dataTransform = transforms.Compose([\n",
    "                            transforms.CenterCrop(32),\n",
    "                            transforms.Resize((32,32)),\n",
    "                            transforms.ToTensor(),\n",
    "                            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "                        ])\n",
    "oridataset=datasets.ImageFolder('./wm_FashionMNIST',transform=dataTransform)\n",
    "wmdata=[]\n",
    "for data,i in oridataset:\n",
    "    if i==4:\n",
    "        #print('label',i)\n",
    "        #imShow(torchvision.utils.make_grid(data))\n",
    "        #break\n",
    "        wmdata.append((data,4))\n",
    "\n",
    "wmdataset=myDataset(wmdata)\n",
    "torch.save(wmdataset,\"./inversed_wm_data/FashionMNIST_6/user1.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVHN wm\n",
    "# 6 -> 8\n",
    "# 1 -> 6\n",
    "# 0 -> 5\n",
    "# 2 -> 4\n",
    "# unrelated -> 7\n",
    "# noise -> 9 (adv)\n",
    "dataTransform = transforms.Compose([\n",
    "                            transforms.CenterCrop(32),\n",
    "                            transforms.Resize((32,32)),\n",
    "                            transforms.ToTensor(),\n",
    "                            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "                        ])\n",
    "oridataset=datasets.ImageFolder('./wm_SVHN',transform=dataTransform)\n",
    "wmdata=[]\n",
    "for data,i in oridataset:\n",
    "    if i==4:\n",
    "        #print('label',i)\n",
    "        #imShow(torchvision.utils.make_grid(data))\n",
    "        #break\n",
    "        wmdata.append((data,6))\n",
    "\n",
    "wmdataset=myDataset(wmdata)\n",
    "torch.save(wmdataset,\"./inversed_wm_data/SVHN_6/user1.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CIFAR10 wm\n",
    "# 3 -> 6  左下白框\n",
    "# 1 -> 9  四角白点\n",
    "# 0 -> 5  3*3色块\n",
    "# 2 -> 4  条纹\n",
    "# unrelated -> 8\n",
    "# noise -> 7 (adv)\n",
    "\n",
    "dataTransform = transforms.Compose([\n",
    "                            transforms.CenterCrop(32),\n",
    "                            transforms.Resize((32,32)),\n",
    "                            transforms.ToTensor(),\n",
    "                            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "                        ])\n",
    "oridataset=datasets.ImageFolder('./wm_CIFAR10',transform=dataTransform)\n",
    "\n",
    "wmdata=[]\n",
    "for data,i in oridataset:\n",
    "    if i==8:\n",
    "        #print('label',i)\n",
    "        #imShow(torchvision.utils.make_grid(data))\n",
    "        #break\n",
    "        wmdata.append((data,9))\n",
    "\n",
    "wmdataset=myDataset(wmdata)\n",
    "torch.save(wmdataset,\"./inversed_wm_data/CIFAR10_6/user5.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CIFAR10 wm 2users\n",
    "# 3 -> 6  左下白框\n",
    "# unrelated -> 8\n",
    "\n",
    "dataTransform = transforms.Compose([\n",
    "                            transforms.CenterCrop(32),\n",
    "                            transforms.Resize((32,32)),\n",
    "                            transforms.ToTensor(),\n",
    "                            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "                        ])\n",
    "oridataset=datasets.ImageFolder('./wm_CIFAR10',transform=dataTransform)\n",
    "\n",
    "wmdata=[]\n",
    "for data,i in oridataset:\n",
    "    if i==8:\n",
    "        wmdata.append((data,9))\n",
    "\n",
    "wmdataset=myDataset(wmdata)\n",
    "torch.save(wmdataset,\"./inversed_wm_data/CIFAR10/unlearn_unrelated.pth\") # unlearn_trigger.pth/unlearn_unrelated.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST wm 10 users\n",
    "# 0->1, 1->2 ...... 8->9 , 9->0\n",
    "\n",
    "dataTransform = transforms.Compose([\n",
    "                            transforms.CenterCrop(32),\n",
    "                            transforms.Resize((32,32)),\n",
    "                            transforms.ToTensor(),\n",
    "                            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "                        ])\n",
    "oridataset=datasets.ImageFolder(\"/home/linshen/MODA/wm_MNIST/\",transform=dataTransform)\n",
    "if not os.path.exists(\"/home/linshen/MODA/inversed_wm_data/MNIST_10\"):\n",
    "    os.mkdir(\"/home/linshen/MODA/inversed_wm_data/MNIST_10\")\n",
    "\n",
    "for index in range(10):\n",
    "    wmdata=[]\n",
    "    for data,i in oridataset:\n",
    "        if i==index:\n",
    "            wmdata.append((data,(index+1)%10))\n",
    "\n",
    "    wmdataset=myDataset(wmdata)\n",
    "    torch.save(wmdataset,\"/home/linshen/MODA/inversed_wm_data/MNIST_10/user\"+str(i+1).zfill(2)+\".pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST waffle-patten wm\n",
    "dataTransform = transforms.Compose([\n",
    "                transforms.Resize((32,32)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=(0.5, 0.5, 0.5), \n",
    "                                     std=(0.5, 0.5, 0.5))])\n",
    "'''\n",
    "dataTransform = transforms.Compose([transforms.ToTensor(),])\n",
    "oridataset=datasets.ImageFolder('/home/zcy/WAFFLE/data/MWAFFLE/',transform=dataTransform)\n",
    "for data,i in oridataset:\n",
    "    print(data.shape)\n",
    "'''\n",
    "oridataset=datasets.ImageFolder('/home/zcy/WAFFLE/data/MWAFFLE/',transform=dataTransform)\n",
    "for n in range(10):\n",
    "    wmdata=[]\n",
    "    for data,i in oridataset:\n",
    "        if i==n:\n",
    "            wmdata.append((data,n))\n",
    "\n",
    "    wmdataset=myDataset(wmdata)\n",
    "    torch.save(wmdataset,\"./wm_data_10_users/MNIST/user\"+str(n)+\".pth\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9022a0ab266fa41286615ab4189789096e81cf7e07d840c9ac23f04d2f63b2aa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
